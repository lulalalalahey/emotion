{"cells":[{"cell_type":"markdown","metadata":{"id":"IqM-T1RTzY6C"},"source":["To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n","<div class=\"align-center\">\n","  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n","  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n","  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n","</div>\n","\n","To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://github.com/unslothai/unsloth?tab=readme-ov-file#-installation-instructions).\n","\n","You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save) (eg for Llama.cpp).\n","\n","**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**\n","\n","Features in the notebook:\n","1. Uses Maxime Labonne's [FineTome 100K](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset.\n","1. Convert ShareGPT to HuggingFace format via `standardize_sharegpt`\n","2. Train on Completions / Assistant only via `train_on_responses_only`\n","3. Unsloth now supports Torch 2.4, all TRL & Xformers versions & Python 3.12!"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"2eSvM9zX_2d3","executionInfo":{"status":"ok","timestamp":1730440804429,"user_tz":-480,"elapsed":246082,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}}},"outputs":[],"source":["%%capture\n","!pip install unsloth\n","# Also get the latest nightly Unsloth!\n","!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""]},{"cell_type":"code","source":[],"metadata":{"id":"yFPqo1XVS7Nv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r2v_X2fA0Df5"},"source":["* We support Llama, Mistral, Phi-3, Gemma, Yi, DeepSeek, Qwen, TinyLlama, Vicuna, Open Hermes etc\n","* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n","* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n","* [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n","* [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351,"referenced_widgets":["36981726dc404df8874bb0796084bced","05fd433f8f484e55afea57b3c1384ff3","cbb84ef62bab4326a6c410e8882c8014","fc34d081a93c4b29a5dcb778b3555cf6","51dc48b88ca1452bbb9aa0b679f0af45","bd9a30b2e2504739b9b3a2f35c0dc3d3","92a90693e6dc4836b144d83340030e14","82c7d899dd18448dbbcd552ba9cf8c15","ae5b1c23929f4778bb44530b150b69e5","d5e37d00bf0247a0b4f0b9644ae21d1d","62f93eb313cc4d79ad21deb4b3041351","c19e4a642f4d469cba01f58b43ba10e5","2148b67075f84b398edbe2bb8240a465","35791f89229048698e2c890b8df8e305","8192e352cf1e4687b3c324f4d6f15292","e1a84d7f539e48c7a4e10181b3ee9e4c","f6524d8a70cb428b8768a9b14dceea24","780d14f6163e4cb5806354c7cc7ff64f","b10aeec1a7cc41c5bedcdf785cad0fd8","c4896e0401df480d9c7a0fc4aa1af3b8","3b874df1fcf84b09b90ea8d01c775a72","f87b04b496d546878d2cb80b592012de","7e3e4c8d3ffb46bf85c83606f20e4d93","30676ce5eab14ebbb01160109cb33b5b","e2d4b8ff64da4dc6a9c2ba693efc2d2b","f7bb0b34d2f74c94a22f940c40bdee58","f9fe991293344132a3f9ae365b1c01ad","17faddb1f5bf4180a203847b32b2ab5b","e23de6c4f0fc4b81aa7d8acb48b21216","9b225dc5593a4f8ea4148a7c9e27c75f","a91f987509a546ce8a66248fa66a1a46","747e2dc242014fecb41f2aa32e664192","cb9a690d5fad40d0845d511d0b1b124e","e5e000d64d7a454da36486967ffc08c8","b0510cec2c45456b99ec434ef9b9157b","411cda0f1a5e4b7e9d74f987c7a2b16a","be2aafaefe814dcd9b13928273a7ba0d","c47488089eb549a4b31044c572fe8eaa","2d00ab237213428faeb77de58d861670","ef82c23c6b0b4a75acad1a703150411c","c65a402ff025440b913ad3b83c1083fd","c008bf66a39a4ea0b6e96621cd7f60b6","4ac66aced16a40ee92aa346863bedf99","d05270121965414982167926a327be7c","a788f319dd1e4615a6a79ef69f034561","1dceacc636e84c9fb1f791cd7d61443b","b5e4cea070294f3ea30578bb0eafca2e","57af8ebf0c964110878cb5881906231d","d41cfc52350e41619550c5e4aa3fab5b","7b2da0a983af4e2cbbdc23f7cebfe57b","98dc0478ab5142a9ad267948441d2dbe","b6e713c99db94de198e03ce6b964dec6","444574265e6b4323a0cb164e95dc0ddc","8a065374ea0f409f87aa64fb72be47ab","274361260632487e90f9c32e82ee0dc3"]},"id":"QmUBVEnvCDJv","outputId":"3ddc4972-cb8e-4893-cec6-7ff4a5086377","executionInfo":{"status":"ok","timestamp":1730440950980,"user_tz":-480,"elapsed":78843,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","==((====))==  Unsloth 2024.10.7: Fast Llama patching. Transformers = 4.44.2.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 7.5. CUDA Toolkit = 12.4.\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36981726dc404df8874bb0796084bced"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c19e4a642f4d469cba01f58b43ba10e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/54.6k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e3e4c8d3ffb46bf85c83606f20e4d93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5e000d64d7a454da36486967ffc08c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a788f319dd1e4615a6a79ef69f034561"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\n","Please update transformers, TRL and unsloth via:\n","`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"]}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n","    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n","    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n","    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n","    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n","    \"unsloth/Phi-3-medium-4k-instruct\",\n","    \"unsloth/gemma-2-9b-bnb-4bit\",\n","    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n","\n","    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n","    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n","    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n","    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"markdown","metadata":{"id":"SXd9bTZd1aaL"},"source":["We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6bZsfBuZDeCL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730441009285,"user_tz":-480,"elapsed":10869,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"d100e5ac-35b1-4733-a868-540530af63b8"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2024.10.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"markdown","metadata":{"id":"vITh0KVJ10qX"},"source":["<a name=\"Data\"></a>\n","### Data Prep\n","We now use the `Llama-3.1` format for conversation style finetunes. We use [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset in ShareGPT style. But we convert it to HuggingFace's normal multiturn format `(\"role\", \"content\")` instead of `(\"from\", \"value\")`/ Llama-3 renders multi turn conversations like below:\n","\n","```\n","<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n","\n","Hello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n","\n","Hey there! How are you?<|eot_id|><|start_header_id|>user<|end_header_id|>\n","\n","I'm great thanks!<|eot_id|>\n","```\n","\n","We use our `get_chat_template` function to get the correct chat template. We support `zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, phi3, llama3` and more."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"LjY75GoYUCB8","executionInfo":{"status":"ok","timestamp":1730441981277,"user_tz":-480,"elapsed":3173,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}}},"outputs":[],"source":["from unsloth.chat_templates import get_chat_template\n","\n","tokenizer = get_chat_template(\n","    tokenizer,\n","    chat_template = \"llama-3.1\",\n",")\n","\n","def formatting_prompts_func(examples):\n","    formatted_texts = []\n","\n","    for i in range(len(examples[\"prompt\"])):\n","        # Ëé∑Âèñ prompt Âíå response\n","        user_prompt = examples[\"prompt\"][i]\n","        response = examples[\"response\"][i]\n","\n","        # ÊûÑÂª∫‰ºöËØùÁªìÊûÑ\n","        conversation = [\n","            {\"role\": \"user\", \"content\": user_prompt},\n","            {\"role\": \"assistant\", \"content\": response},\n","            {\n","                \"role\": \"system\",\n","                \"content\": f\"Helpfulness: {examples['helpfulness'][i]}, Correctness: {examples['correctness'][i]}, Coherence: {examples['coherence'][i]}, Complexity: {examples['complexity'][i]}, Verbosity: {examples['verbosity'][i]}\"\n","            }\n","        ]\n","\n","        # Â∫îÁî®Ê®°ÊùøÊ†ºÂºèÂåñ\n","        formatted_text = tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=False)\n","        formatted_texts.append(formatted_text)\n","\n","    # Á°Æ‰øùËæìÂá∫ÁöÑÈïøÂ∫¶‰∏éËæìÂÖ•‰∏ÄËá¥\n","    if len(formatted_texts) < len(examples[\"prompt\"]):\n","        formatted_texts.extend([\"\"] * (len(examples[\"prompt\"]) - len(formatted_texts)))  # Áî®Á©∫Â≠óÁ¨¶‰∏≤Â°´ÂÖÖÁº∫Â∞ëÁöÑÊù°ÁõÆ\n","\n","    return {\"text\": formatted_texts}\n","\n","\n","from datasets import load_dataset\n","dataset = load_dataset(\"nvidia/HelpSteer2\", split = \"train\")"]},{"cell_type":"code","source":["print(dataset[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"djZrzygDV1sC","executionInfo":{"status":"ok","timestamp":1730441353699,"user_tz":-480,"elapsed":501,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"00b5280b-a45a-4339-8a5a-3822eca68a74"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["{'prompt': 'c#', 'response': 'C# is a high-level, object-oriented programming language developed by Microsoft as part of its .NET initiative. It was created as a modern alternative to Java and supports a variety of programming paradigms, including imperative, functional, and event-driven. C# is primarily used for Windows application development, but it can also be used for web, mobile, and game development. The language is designed to be safe, secure, and efficient, and it provides developers with a rich set of libraries and tools for building robust and scalable applications. C# is also widely used in the game development industry, particularly in the development of games for the Xbox 360 and Xbox One consoles.', 'helpfulness': 3, 'correctness': 4, 'coherence': 4, 'complexity': 2, 'verbosity': 1}\n"]}]},{"cell_type":"markdown","source":["```\n","An example looks like\n","\n","{\n","    \"split\": \"train\",\n","    \"prompt\": \"Define Signal Discuss its various properties with the help of diagram\",\n","    \"response_1\": \"A signal is a form of energy that is used to transmit information from one place to another. It can be in the form of sound, light, radio waves, or any other form of energy that can be detected by a sensor or receiver.\\n\\nThe properties of a signal can be described by its amplitude, frequency, and phase.\\n\\nAmplitude: The amplitude of a signal is the measure of its strength or intensity. It is usually measured in volts or watts.\\n\\nFrequency: The frequency of a signal is the measure of how many times it repeats itself in a given period of time. It is usually measured in Hertz (Hz).\\n\\nPhase: The phase of a signal is the measure of its position in time. It is usually measured in degrees or radians.\\n\\nA signal can be represented by a graph that shows its amplitude or intensity over time. This graph is called a waveform. The shape of the waveform can provide information about the type of signal and the information it carries.\",\n","    \"response_2\": \"A signal is a message that is conveyed from a sender to a receiver through a communication channel. The message can be in the form of a sound, light, electrical, or any other form that can be transmitted and received. The properties of a signal can vary depending on the type of signal and the communication channel used. Here are some common properties of signals:\\n\\nAmplitude: This is the maximum value that a signal can take. It represents the strength of the signal. For example, in an electrical signal, amplitude can be measured in volts.\\n\\nFrequency: This is the number of cycles or oscillations of a signal per unit time. It is measured in hertz (Hz). For example, a sound signal with a frequency of 20 Hz vibrates 20 times per second.\\n\\nWavelength: This is the distance between two successive crests or troughs of a signal. It is measured in meters (m). For example, in a light signal, wavelength can be measured in nanometers (nm).\\n\\nPhase: This is the position of a signal with respect to a reference signal. It is measured in degrees (\\u00b0) or radians (rad). For example, in an electrical signal, phase can be measured in relation to a reference signal.\\n\\nEnvelope: This is the curve that bounds the amplitude of a signal. It can be used to represent the shape of a signal. For example, in an audio signal, the envelope can represent the shape of a musical note.\\n\\nNoise: This is any unwanted or random variation in a signal that can affect its quality. It can be caused by various sources such as interference, interference, or natural phenomena.\\n\\nHere is a diagram that represents the properties of a signal:\\n\\n\\nAmplitude\\nFrequency\\nWavelength\\nPhase\\nEnvelope\\nNoise\\n\\n\\nThe diagram shows how each property can affect the shape and quality of a signal. The presence of noise can degrade the quality of a signal and make it difficult to interpret. The properties of a signal can be controlled and optimized to ensure that the message is conveyed accurately and efficiently.\",\n","    \"preference_strength\": 1,\n","    \"preference_statement\": \"@Response 2 is better than @Response 1 because it provides a comprehensive insightful explanation of signanal and its properties.\",\n","    \"preference_elaboration\": \"It is complete, clear and correct as it discuss all the the poperties of signal while @Response 1 only discusses  three properties of signal. It does not diuscuss important properties like noise, phase and envelope. @Response 2  follows all the instruction but @Response 1 does not follow all the instruction. For instance the instruction requires an explanation of signal and its properties with an aid of a diagram but @Response 1 does not provide the diagram.\",\n","    \"three_most_similar_preferences\": [\n","        {\n","            \"statement\": \"@Response 2 is better than @Response 1 because it provides a comprehensive insightful explanation of signanal and its properties.\",\n","            \"elaboration\": \"It is complete, clear and correct as it discuss all the the poperties of signal while @Response 1 only discusses  three properties of signal. It does not diuscuss important properties like noise, phase and envelope. @Response 2  follows all the instruction but @Response 1 does not follow all the instruction. For instance the instruction requires an explanation of signal and its properties with an aid of a diagram but @Response 1 does not provide the diagram.\",\n","            \"strength\": 1\n","        },\n","        {\n","            \"statement\": \"@Response 2 is slightly better than @Response 1.\",\n","            \"elaboration\": \"@Response 2 goes into detail about the different types of signals that can be used for transmittal. Providing these topics gives a full overview of Signal Discuss. That makes this prompt complete, extremely helpful, and it is well-written. This response uses a paragraph format which breaks up the change in topic. @Response 1 covers a signal in less detail. It leaves out wavelengths, noise, and envelop as a way to transmit information from one network to another. This is not necessarily bad, but it is not in full detail.\",\n","            \"strength\": 1\n","        },\n","        {\n","            \"statement\": \"@Response 2 is slightly better than @Response 1 because it includes the diagram as requested by the prompt, which @Response 1 does not.\",\n","            \"elaboration\": \"However, @Response 2 does have issues with **correctness**: irrelevant terms like \\\"envelope\\\" are typically properties of the diagram, not the signal. **Formatting** could also be improved for @Response 2. While the diagram is included, it does not display correctly and the word \\\"interference\\\" is erroneously repeated twice.\",\n","            \"strength\": 1\n","        }\n","    ],\n","    \"all_preferences_unprocessed\": [\n","        {\n","            \"strength\": 1,\n","            \"justification\": \"@Response 2 is better than @Response 1 because it provides a comprehensive insightful explanation of signanal and its properties. It is complete, clear and correct as it discuss all the the poperties of signal while @Response 1 only discusses  three properties of signal. It does not diuscuss important properties like noise, phase and envelope. @Response 2  follows all the instruction but @Response 1 does not follow all the instruction. For instance the instruction requires an explanation of signal and its properties with an aid of a diagram but @Response 1 does not provide the diagram.\"\n","        },\n","        {\n","            \"strength\": 1,\n","            \"justification\": \"@Response 2 is slightly better than @Response 1. @Response 2 goes into detail about the different types of signals that can be used for transmittal. Providing these topics gives a full overview of Signal Discuss. That makes this prompt complete, extremely helpful, and it is well-written. This response uses a paragraph format which breaks up the change in topic. @Response 1 covers a signal in less detail. It leaves out wavelengths, noise, and envelop as a way to transmit information from one network to another. This is not necessarily bad, but it is not in full detail.\"\n","        },\n","        {\n","            \"strength\": 1,\n","            \"justification\": \"@Response 2 is slightly better than @Response 1 because it includes the diagram as requested by the prompt, which @Response 1 does not. However, @Response 2 does have issues with **correctness**: irrelevant terms like \\\"envelope\\\" are typically properties of the diagram, not the signal. **Formatting** could also be improved for @Response 2. While the diagram is included, it does not display correctly and the word \\\"interference\\\" is erroneously repeated twice. Although @Response 1 is more succinct and the writing style flows better, it falls short in **instructions following** and therefore @Response 2 is slightly better.\"\n","        }\n","    ]\n","}\n","```"],"metadata":{"id":"OGBTtmJUVoVT"}},{"cell_type":"code","source":[],"metadata":{"id":"Gcg4Tm4FVm74"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We now use `standardize_sharegpt` to convert ShareGPT style datasets into HuggingFace's generic format. This changes the dataset from looking like:\n","```\n","{\"from\": \"system\", \"value\": \"You are an assistant\"}\n","{\"from\": \"human\", \"value\": \"What is 2+2?\"}\n","{\"from\": \"gpt\", \"value\": \"It's 4.\"}\n","```\n","to\n","```\n","{\"role\": \"system\", \"content\": \"You are an assistant\"}\n","{\"role\": \"user\", \"content\": \"What is 2+2?\"}\n","{\"role\": \"assistant\", \"content\": \"It's 4.\"}\n","```"],"metadata":{"id":"K9CBpiISFa6C"}},{"cell_type":"code","source":["dataset = dataset.map(formatting_prompts_func, batched=True)\n"],"metadata":{"id":"oPXzJZzHEgXe","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["dacc09fa32084dd4ac05c1fa6c659279","f7d92a9b70a14f19a40e34082ace404f","3f92dc6931e14b1187abf4d429eec0ca","b421abc9b1d34422975aaeb73e1d8438","fabb313182a842a787c501a0b588b3f7","d3acb5ec73704903a3cb2c12c97f9166","429d2b5b990f408d854e6b97e7d7f3ec","e7f1400c0da64a32b88ea92979f039e5","16b30041863a4fa6827768ea8c4307a4","2952fff73a0a4191a97f152d11e46453","90b3be7f36b34f468dbd925da6d022f8"]},"executionInfo":{"status":"ok","timestamp":1730441990785,"user_tz":-480,"elapsed":3379,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"eb832fd3-0a54-4e19-cbd7-3f0d7d2b0a9a"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/20324 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dacc09fa32084dd4ac05c1fa6c659279"}},"metadata":{}}]},{"cell_type":"markdown","source":["We look at how the conversations are structured for item 5:"],"metadata":{"id":"ndDUB23CGAC5"}},{"cell_type":"code","source":["print(dataset[0:5])  # ËßÇÂØüÊ†áÂáÜÂåñÂêéÊï∞ÊçÆÁöÑÁªìÊûÑ\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmiIiuL_WDlG","executionInfo":{"status":"ok","timestamp":1730443047089,"user_tz":-480,"elapsed":530,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"5b91396a-103c-4a0d-a829-332d3ca7011b"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["{'prompt': ['c#', 'c#', 'bacillus subtilus', 'bacillus subtilus', 'Write long detailed essay about ancient type of religion, totemism'], 'response': ['C# is a high-level, object-oriented programming language developed by Microsoft as part of its .NET initiative. It was created as a modern alternative to Java and supports a variety of programming paradigms, including imperative, functional, and event-driven. C# is primarily used for Windows application development, but it can also be used for web, mobile, and game development. The language is designed to be safe, secure, and efficient, and it provides developers with a rich set of libraries and tools for building robust and scalable applications. C# is also widely used in the game development industry, particularly in the development of games for the Xbox 360 and Xbox One consoles.', 'C# (pronounced \"C sharp\") is a modern, object-oriented programming language developed by Microsoft. It is widely used for building various types of applications, including web applications, desktop applications, mobile applications, and games. C# is similar to other programming languages such as Java and C++, and it is known for its simplicity and ease of use. C# is a powerful language that provides a rich set of libraries and frameworks that make it easy to build robust and scalable applications.\\n\\nHere is a brief overview of some key features of C#:\\n\\n1. Object-oriented: C# is an object-oriented language, which means it uses the concept of objects to represent real-world entities and their behavior.\\n\\n2. Cross-platform: C# can be used to build applications for multiple platforms, including Windows, macOS, and Linux.\\n\\n3. Strongly typed: C# is a strongly typed language, which means that variables must be declared with a specific type, and their type cannot be changed at runtime.\\n\\n4. Event-driven: C# uses an event-driven programming model, which means that programs are built around the concept of events, such as user input or network activity.\\n\\n5. Garbage-collected: C# has a garbage collector that automatically manages memory allocation and deallocation, making it easier to write memory-efficient and robust applications.\\n\\n6. Community-driven: C# has a large and active community of developers, who contribute to the language and its libraries through open-source projects and other initiatives.\\n\\nOverall, C# is a versatile and powerful programming language that is widely used for building a variety of applications.', 'Bacillus subtilis is a Gram-positive, rod-shaped bacterium commonly found in soil and water. It is a facultative anaerobe that can grow in the presence or absence of oxygen. B. subtilis is a model organism for studying bacterial cell biology, genetics, and physiology, and has many industrial and medical applications.\\n\\nB. subtilis is a versatile organism with many interesting properties. It can form spores that allow it to survive harsh environmental conditions, such as heat, cold, and dehydration. The spores can remain dormant for long periods of time and then germinate when conditions are favorable. B. subtilis can also produce a variety of enzymes, antibiotics, and other compounds that have industrial and medical applications.\\n\\nB. subtilis has been used in the production of enzymes for industrial applications, such as in the food and beverage industry for the production of cheese, yogurt, and beer. It is also used in the production of antibiotics and other pharmaceutical compounds. B. subtilis is also a model organism for studying bacterial cell biology, genetics, and physiology, and has been used extensively in research to study the mechanisms of bacterial growth, development, and survival.\\n\\nOverall, B. subtilis is a versatile and important organism with many industrial and medical applications. Its properties and behaviors make it a valuable tool for researchers and industry alike.', 'The Bacillus subtilis is a Gram-positive, endospore-forming bacterium that is commonly found in the environment, such as in soil and on plants. It is a rod-shaped bacterium that can grow in a wide range of temperatures and pH levels.\\n\\nBacillus subtilis is a common bacterium used in the food and beverage industry as a starter culture for the production of fermented foods, such as yogurt and sauerkraut. It is also used in the production of various enzymes, such as amylase and protease, which are used in the baking, brewing, and detergent industries.\\n\\nBacillus subtilis has also been studied for its potential use in biotechnology and medicine. It has been shown to have antimicrobial activity against some pathogens and is being studied for its potential use in the treatment of infections and other diseases. Additionally, some strains of Bacillus subtilis have been shown to produce antibiotics, such as bacitracin, which can be used to treat bacterial infections.\\n\\nOverall, Bacillus subtilis is a versatile and important bacterium that has a wide range of applications in various industries and fields of study.', 'Totemism is an ancient type of religion that is characterized by the belief that humans are related to and have a special connection with certain animals, plants, or natural phenomena. These objects or beings are considered to be totems, and they are believed to have spiritual and symbolic significance.\\n\\nIn totemism, individuals are thought to have a special relationship with their own personal totem, which is believed to be a spirit that watches over them and provides guidance and protection. Totems are also associated with certain clans or groups of people, and these groups are often named after the animal or plant that is their totem.\\n\\nTotemism is found in many cultures around the world, including among Native Americans, Australian Aboriginals, and some tribes in Africa and Asia. In these cultures, totems are often represented in art, mythology, and ritual, and they play an important role in the spiritual and cultural life of the community.\\n\\nOne of the key features of totemism is the idea of animal totems. These are animals that are believed to have a special connection with humans, and they are often seen as symbols of power, strength, and wisdom. For example, the eagle is a common animal totem among Native Americans, and it is associated with qualities such as courage, vision, and freedom.\\n\\nAnother important aspect of totemism is the idea of totemic ancestor worship. This involves the belief that the spirits of ancestors are associated with certain totems, and that by honoring these totems, we can honor our ancestors and maintain a connection with them.\\n\\nIn many cultures, totemism is also linked to the idea of totemic law. This involves the belief that the laws and customs of a tribe are associated with their totems, and that by following these laws, individuals can maintain a connection with their totems and ensure their well-being.\\n\\nOverall, totemism is a fascinating and complex type of religion that has played an important role in many cultures around the world. It is a reminder of the deep connection that humans have with the natural world, and it provides a rich source of spiritual and cultural heritage that continues to inspire and inform many modern cultures today.'], 'helpfulness': [3, 4, 4, 3, 3], 'correctness': [4, 4, 4, 4, 3], 'coherence': [4, 4, 4, 3, 3], 'complexity': [2, 2, 3, 3, 2], 'verbosity': [1, 3, 3, 2, 2], 'text': ['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nc#<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nC# is a high-level, object-oriented programming language developed by Microsoft as part of its .NET initiative. It was created as a modern alternative to Java and supports a variety of programming paradigms, including imperative, functional, and event-driven. C# is primarily used for Windows application development, but it can also be used for web, mobile, and game development. The language is designed to be safe, secure, and efficient, and it provides developers with a rich set of libraries and tools for building robust and scalable applications. C# is also widely used in the game development industry, particularly in the development of games for the Xbox 360 and Xbox One consoles.<|eot_id|><|start_header_id|>system<|end_header_id|>\\n\\nHelpfulness: 3, Correctness: 4, Coherence: 4, Complexity: 2, Verbosity: 1<|eot_id|>', '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nc#<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nC# (pronounced \"C sharp\") is a modern, object-oriented programming language developed by Microsoft. It is widely used for building various types of applications, including web applications, desktop applications, mobile applications, and games. C# is similar to other programming languages such as Java and C++, and it is known for its simplicity and ease of use. C# is a powerful language that provides a rich set of libraries and frameworks that make it easy to build robust and scalable applications.\\n\\nHere is a brief overview of some key features of C#:\\n\\n1. Object-oriented: C# is an object-oriented language, which means it uses the concept of objects to represent real-world entities and their behavior.\\n\\n2. Cross-platform: C# can be used to build applications for multiple platforms, including Windows, macOS, and Linux.\\n\\n3. Strongly typed: C# is a strongly typed language, which means that variables must be declared with a specific type, and their type cannot be changed at runtime.\\n\\n4. Event-driven: C# uses an event-driven programming model, which means that programs are built around the concept of events, such as user input or network activity.\\n\\n5. Garbage-collected: C# has a garbage collector that automatically manages memory allocation and deallocation, making it easier to write memory-efficient and robust applications.\\n\\n6. Community-driven: C# has a large and active community of developers, who contribute to the language and its libraries through open-source projects and other initiatives.\\n\\nOverall, C# is a versatile and powerful programming language that is widely used for building a variety of applications.<|eot_id|><|start_header_id|>system<|end_header_id|>\\n\\nHelpfulness: 4, Correctness: 4, Coherence: 4, Complexity: 2, Verbosity: 3<|eot_id|>', '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nbacillus subtilus<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nBacillus subtilis is a Gram-positive, rod-shaped bacterium commonly found in soil and water. It is a facultative anaerobe that can grow in the presence or absence of oxygen. B. subtilis is a model organism for studying bacterial cell biology, genetics, and physiology, and has many industrial and medical applications.\\n\\nB. subtilis is a versatile organism with many interesting properties. It can form spores that allow it to survive harsh environmental conditions, such as heat, cold, and dehydration. The spores can remain dormant for long periods of time and then germinate when conditions are favorable. B. subtilis can also produce a variety of enzymes, antibiotics, and other compounds that have industrial and medical applications.\\n\\nB. subtilis has been used in the production of enzymes for industrial applications, such as in the food and beverage industry for the production of cheese, yogurt, and beer. It is also used in the production of antibiotics and other pharmaceutical compounds. B. subtilis is also a model organism for studying bacterial cell biology, genetics, and physiology, and has been used extensively in research to study the mechanisms of bacterial growth, development, and survival.\\n\\nOverall, B. subtilis is a versatile and important organism with many industrial and medical applications. Its properties and behaviors make it a valuable tool for researchers and industry alike.<|eot_id|><|start_header_id|>system<|end_header_id|>\\n\\nHelpfulness: 4, Correctness: 4, Coherence: 4, Complexity: 3, Verbosity: 3<|eot_id|>', '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nbacillus subtilus<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe Bacillus subtilis is a Gram-positive, endospore-forming bacterium that is commonly found in the environment, such as in soil and on plants. It is a rod-shaped bacterium that can grow in a wide range of temperatures and pH levels.\\n\\nBacillus subtilis is a common bacterium used in the food and beverage industry as a starter culture for the production of fermented foods, such as yogurt and sauerkraut. It is also used in the production of various enzymes, such as amylase and protease, which are used in the baking, brewing, and detergent industries.\\n\\nBacillus subtilis has also been studied for its potential use in biotechnology and medicine. It has been shown to have antimicrobial activity against some pathogens and is being studied for its potential use in the treatment of infections and other diseases. Additionally, some strains of Bacillus subtilis have been shown to produce antibiotics, such as bacitracin, which can be used to treat bacterial infections.\\n\\nOverall, Bacillus subtilis is a versatile and important bacterium that has a wide range of applications in various industries and fields of study.<|eot_id|><|start_header_id|>system<|end_header_id|>\\n\\nHelpfulness: 3, Correctness: 4, Coherence: 3, Complexity: 3, Verbosity: 2<|eot_id|>', '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWrite long detailed essay about ancient type of religion, totemism<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nTotemism is an ancient type of religion that is characterized by the belief that humans are related to and have a special connection with certain animals, plants, or natural phenomena. These objects or beings are considered to be totems, and they are believed to have spiritual and symbolic significance.\\n\\nIn totemism, individuals are thought to have a special relationship with their own personal totem, which is believed to be a spirit that watches over them and provides guidance and protection. Totems are also associated with certain clans or groups of people, and these groups are often named after the animal or plant that is their totem.\\n\\nTotemism is found in many cultures around the world, including among Native Americans, Australian Aboriginals, and some tribes in Africa and Asia. In these cultures, totems are often represented in art, mythology, and ritual, and they play an important role in the spiritual and cultural life of the community.\\n\\nOne of the key features of totemism is the idea of animal totems. These are animals that are believed to have a special connection with humans, and they are often seen as symbols of power, strength, and wisdom. For example, the eagle is a common animal totem among Native Americans, and it is associated with qualities such as courage, vision, and freedom.\\n\\nAnother important aspect of totemism is the idea of totemic ancestor worship. This involves the belief that the spirits of ancestors are associated with certain totems, and that by honoring these totems, we can honor our ancestors and maintain a connection with them.\\n\\nIn many cultures, totemism is also linked to the idea of totemic law. This involves the belief that the laws and customs of a tribe are associated with their totems, and that by following these laws, individuals can maintain a connection with their totems and ensure their well-being.\\n\\nOverall, totemism is a fascinating and complex type of religion that has played an important role in many cultures around the world. It is a reminder of the deep connection that humans have with the natural world, and it provides a rich source of spiritual and cultural heritage that continues to inspire and inform many modern cultures today.<|eot_id|><|start_header_id|>system<|end_header_id|>\\n\\nHelpfulness: 3, Correctness: 3, Coherence: 3, Complexity: 2, Verbosity: 2<|eot_id|>']}\n"]}]},{"cell_type":"code","source":["print(dataset.column_names)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sluKPl7DZCjg","executionInfo":{"status":"ok","timestamp":1730442179752,"user_tz":-480,"elapsed":498,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"696495df-a97e-4330-f094-281001feb8ed"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["['prompt', 'response', 'helpfulness', 'correctness', 'coherence', 'complexity', 'verbosity', 'text']\n"]}]},{"cell_type":"code","source":["print(len(dataset))  # Ê£ÄÊü•Êò†Â∞ÑÂâçÂêéÁöÑÊï∞ÊçÆÊù°Êï∞ÊòØÂê¶‰∏ÄËá¥\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6DlxA8qMZF0o","executionInfo":{"status":"ok","timestamp":1730442193395,"user_tz":-480,"elapsed":2,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"08c00fad-38f4-4e34-ac78-d7778e544176"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["20324\n"]}]},{"cell_type":"markdown","source":["And we see how the chat template transformed these conversations.\n","\n","**[Notice]** Llama 3.1 Instruct's default chat template default adds `\"Cutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\"`, so do not be alarmed!"],"metadata":{"id":"GfzTdMtvGE6w"}},{"cell_type":"code","source":["dataset[5][\"text\"]"],"metadata":{"id":"vhXv0xFMGNKE","colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"status":"ok","timestamp":1729210180879,"user_tz":420,"elapsed":42,"user":{"displayName":"Daniel Han-Chen","userId":"17402123517466114840"}},"outputId":"07bf64e3-4c5c-430e-e4d5-3ed3cdf21b81"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAstronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"idAEIeSQ3xdS"},"source":["<a name=\"Train\"></a>\n","### Train the model\n","Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"95_Nn-89DhsL","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["d5676a3c878a4cef81a99f98788465c6","3db54d2307c64b35ae7157bf8b733d58","4798e594e9594df5b63bce4b8e6dce18","71dd64dcd81e4fe79e99dbdd3f804456","8e7a93d448054905b7839f3a8cc8e1c9","e6251c41a3dd47b892077fab6113bcff","8d44da7875eb423eb1d2bb9623bb7bd0","5beae692604e4460ae1975884955839e","18218191ebd54e87aa2cc6e4b80f6fc6","541be1b16245403b97a9d03e0c5b72b4","ac60dce9cbd74d839c0ec3eb38fb7e25"]},"executionInfo":{"status":"ok","timestamp":1730442257414,"user_tz":-480,"elapsed":34570,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"2291fd42-b773-460c-a98a-cfc796847dbb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/20324 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5676a3c878a4cef81a99f98788465c6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments, DataCollatorForSeq2Seq\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        # num_train_epochs = 1, # Set this for 1 full training run.\n","        max_steps = 60,\n","        learning_rate = 2e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","        report_to = \"none\", # Use this for WandB etc\n","    ),\n",")"]},{"cell_type":"markdown","source":["We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs."],"metadata":{"id":"C_sGp5XlG6dq"}},{"cell_type":"code","source":["from unsloth.chat_templates import train_on_responses_only\n","trainer = train_on_responses_only(\n","    trainer,\n","    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n","    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",")"],"metadata":{"id":"juQiExuBG5Bt","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["0dcb6023d8e54723a1913eb205834d6a","e12ec3a0303b4871b56a26fde0e89b07","bd20a87c57d04290b2808741d02b0a5c","9250dacb867c4ac2b171367c406cdd6a","8293e636a0d84aa7ad68de3b9601c490","50ea9655e9fa4f90b513334587ad5ec9","debb3d463a224f36b9e03a0121d9861e","d4e8619ca0d848ac83b1d287c0ddf673","2fa1bf55bafb4f4fb26f5b0b5783ac43","2dafbbef96d44849a2798dfdafb8f747","5620f476f6c14befbfcf77d48cbd3d39"]},"executionInfo":{"status":"ok","timestamp":1730442322465,"user_tz":-480,"elapsed":10640,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"db271c0a-9f4e-42f7-d91b-6d4414ca914b"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/20324 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dcb6023d8e54723a1913eb205834d6a"}},"metadata":{}}]},{"cell_type":"markdown","source":["We verify masking is actually done:"],"metadata":{"id":"Dv1NBUozV78l"}},{"cell_type":"code","source":["tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"],"metadata":{"id":"LtsMVtlkUhja","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"ok","timestamp":1730442325660,"user_tz":-480,"elapsed":917,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"f218d606-9653-47ae-c653-5e6b81dc9445"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWrite long detailed essay about ancient type of religion, totemism<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nTotemism is an ancient religious and philosophical system that has been practiced by many cultures around the world for thousands of years. It is based on the belief that all living things, including animals, plants, and natural elements, have a spiritual essence that is connected to the larger world. In this essay, we will explore the history, beliefs, and practices of totemism, as well as its impact on modern culture and spirituality.\\n\\nThe origins of totemism are not entirely clear, but it is believed to have originated in ancient times, possibly as early as the Paleolithic era. The practice has been found in many different cultures around the world, including Native American, Australian, African, and Asian cultures. In many cases, totemism was closely tied to the local environment and the natural world, and it was often used as a way to honor and respect the animals, plants, and natural elements that were an integral part of daily life.\\n\\nAt its core, totemism is based on the belief that all living things have a spiritual essence that is connected to the larger world. This essence is often referred to as a \"totem,\" which is a term that comes from the Ojibwe language. Totems can take many different forms, including animals, plants, natural elements, and even objects such as rocks or trees. Each totem is seen as a symbol of the spiritual power and energy that is present in the world, and it is often associated with specific qualities or characteristics, such as strength, wisdom, or healing.\\n\\nOne of the key aspects of totemism is the idea of \"totemism,\" which is the belief that one\\'s own totem is a reflection of one\\'s personal identity and spiritual essence. In many cultures, people are born with a specific totem that is associated with their family or tribe, and this totem is seen as a representation of their spiritual heritage. People may also choose to adopt a specific totem as a way to connect with a particular aspect of their spiritual identity.\\n\\nIn terms of practices, totemism often involves a variety of rituals and ceremonies that are designed to honor and connect with the spiritual power of the totems. These practices may include things like animal or plant offerings, dance and music, and the use of totemic symbols in art and architecture. In some cultures, totems are also used in healing ceremonies, as a way to connect with the spiritual power of the natural world and to restore balance and harmony to the body and mind.\\n\\nDespite its ancient origins, totemism continues to have an impact on modern culture and spirituality. Many modern spiritual practices, such as shamanism and nature-based spirituality, have roots in totemism, and many people continue to use totems as a way to connect with the spiritual power of the natural world. In addition, the concept of totemism has been adopted by many modern cultures, including some Native American and Australian communities, as a way to preserve traditional cultural practices and to connect with the spiritual heritage of their ancestors.\\n\\nIn conclusion, totemism is an ancient religious and philosophical system that has been practiced by many cultures around the world for thousands of years. It is based on the belief that all living things have a spiritual essence that is connected to the larger world, and it involves a variety of rituals and ceremonies that are designed to honor and connect with the spiritual power of the totems. Despite its ancient origins, totemism continues to have an impact on modern culture and spirituality, and it remains an important part of many traditional cultural practices around the world.<|eot_id|><|start_header_id|>system<|end_header_id|>\\n\\nHelpfulness: 3, Correctness: 3, Coherence: 3, Complexity: 2, Verbosity: 3<|eot_id|>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n","tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"],"metadata":{"id":"_rD6fl8EUxnG","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"ok","timestamp":1730442328776,"user_tz":-480,"elapsed":504,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"f3c7670b-1c3a-4ab5-b50f-c4d3faa38880"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'                                               \\n\\nTotemism is an ancient religious and philosophical system that has been practiced by many cultures around the world for thousands of years. It is based on the belief that all living things, including animals, plants, and natural elements, have a spiritual essence that is connected to the larger world. In this essay, we will explore the history, beliefs, and practices of totemism, as well as its impact on modern culture and spirituality.\\n\\nThe origins of totemism are not entirely clear, but it is believed to have originated in ancient times, possibly as early as the Paleolithic era. The practice has been found in many different cultures around the world, including Native American, Australian, African, and Asian cultures. In many cases, totemism was closely tied to the local environment and the natural world, and it was often used as a way to honor and respect the animals, plants, and natural elements that were an integral part of daily life.\\n\\nAt its core, totemism is based on the belief that all living things have a spiritual essence that is connected to the larger world. This essence is often referred to as a \"totem,\" which is a term that comes from the Ojibwe language. Totems can take many different forms, including animals, plants, natural elements, and even objects such as rocks or trees. Each totem is seen as a symbol of the spiritual power and energy that is present in the world, and it is often associated with specific qualities or characteristics, such as strength, wisdom, or healing.\\n\\nOne of the key aspects of totemism is the idea of \"totemism,\" which is the belief that one\\'s own totem is a reflection of one\\'s personal identity and spiritual essence. In many cultures, people are born with a specific totem that is associated with their family or tribe, and this totem is seen as a representation of their spiritual heritage. People may also choose to adopt a specific totem as a way to connect with a particular aspect of their spiritual identity.\\n\\nIn terms of practices, totemism often involves a variety of rituals and ceremonies that are designed to honor and connect with the spiritual power of the totems. These practices may include things like animal or plant offerings, dance and music, and the use of totemic symbols in art and architecture. In some cultures, totems are also used in healing ceremonies, as a way to connect with the spiritual power of the natural world and to restore balance and harmony to the body and mind.\\n\\nDespite its ancient origins, totemism continues to have an impact on modern culture and spirituality. Many modern spiritual practices, such as shamanism and nature-based spirituality, have roots in totemism, and many people continue to use totems as a way to connect with the spiritual power of the natural world. In addition, the concept of totemism has been adopted by many modern cultures, including some Native American and Australian communities, as a way to preserve traditional cultural practices and to connect with the spiritual heritage of their ancestors.\\n\\nIn conclusion, totemism is an ancient religious and philosophical system that has been practiced by many cultures around the world for thousands of years. It is based on the belief that all living things have a spiritual essence that is connected to the larger world, and it involves a variety of rituals and ceremonies that are designed to honor and connect with the spiritual power of the totems. Despite its ancient origins, totemism continues to have an impact on modern culture and spirituality, and it remains an important part of many traditional cultural practices around the world.<|eot_id|><|start_header_id|>system<|end_header_id|>\\n\\nHelpfulness: 3, Correctness: 3, Coherence: 3, Complexity: 2, Verbosity: 3<|eot_id|>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["We can see the System and Instruction prompts are successfully masked!"],"metadata":{"id":"3enWUM0jV-jV"}},{"cell_type":"code","execution_count":22,"metadata":{"id":"2ejIt2xSNKKp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730442876192,"user_tz":-480,"elapsed":481,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"bedc9c0c-9e82-4a0c-fe12-067e8beab253"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","5.846 GB of memory reserved.\n"]}],"source":["#@title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"yqxqAZ7KJ4oL","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1730442779641,"user_tz":-480,"elapsed":445674,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"39942588-9aba-4213-e586-9c4ee2f2fba4"},"outputs":[{"output_type":"stream","name":"stdout","text":["**** Unsloth: Please use our fixed gradient_accumulation_steps by updating transformers, TRL and Unsloth!\n","`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"]},{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 20,324 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 60\n"," \"-____-\"     Number of trainable parameters = 24,313,856\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 07:05, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.474800</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.158000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.338700</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.121800</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.214000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.468800</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.130700</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.054800</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.917100</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.687300</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.820200</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.837000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>1.005400</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.772500</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.939200</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.601800</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>1.130700</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.762700</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.633300</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.656000</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.728200</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.830900</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.644800</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.723800</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.707900</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>1.312000</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.779900</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.712700</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.757300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.975300</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.677200</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.666600</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>1.026400</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.879500</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.881300</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.820100</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.805700</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.863700</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.730200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.723000</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.696800</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.692200</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.614100</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.531000</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.601300</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.636600</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.756900</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.667600</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.727300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.627200</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.752000</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.754300</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.782800</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.612500</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.735300</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.755500</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.819200</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.724800</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.706000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.729500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"pCqnaKmlO1U9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730442880095,"user_tz":-480,"elapsed":513,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"6d3dc250-f6df-4c8f-ae4d-ce95efed32d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["439.6952 seconds used for training.\n","7.33 minutes used for training.\n","Peak reserved memory = 5.846 GB.\n","Peak reserved memory for training = 0.0 GB.\n","Peak reserved memory % of max memory = 39.639 %.\n","Peak reserved memory for training % of max memory = 0.0 %.\n"]}],"source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"]},{"cell_type":"markdown","metadata":{"id":"ekOmTR1hSNcr"},"source":["<a name=\"Inference\"></a>\n","### Inference\n","Let's run the model! You can change the instruction and input - leave the output blank!\n","\n","**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**\n","\n","We use `min_p = 0.1` and `temperature = 1.5`. Read this [Tweet](https://x.com/menhguin/status/1826132708508213629) for more information on why."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"kR3gIAX-SM2q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730442888952,"user_tz":-480,"elapsed":5092,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"d3f9a0cf-5e9a-46c6-be35-a828f5c8e2bf"},"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"output_type":"execute_result","data":{"text/plain":["[\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nContinue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe Fibonacci sequence is a series of numbers in which each number is the sum of the two preceding numbers, starting from 1 and 1. It's a mathematical concept used to describe patterns in the natural world, like the number of leaves on a stem or the branching of trees.\\n\\nHere's the Fibonacci sequence up to\"]"]},"metadata":{},"execution_count":24}],"source":["from unsloth.chat_templates import get_chat_template\n","\n","tokenizer = get_chat_template(\n","    tokenizer,\n","    chat_template = \"llama-3.1\",\n",")\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","messages = [\n","    {\"role\": \"user\", \"content\": \"Continue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,\"},\n","]\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize = True,\n","    add_generation_prompt = True, # Must add for generation\n","    return_tensors = \"pt\",\n",").to(\"cuda\")\n","\n","outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n","                         temperature = 1.5, min_p = 0.1)\n","tokenizer.batch_decode(outputs)"]},{"cell_type":"markdown","metadata":{"id":"CrSvZObor0lY"},"source":[" You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"e2pEuRb1r2Vg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730442896303,"user_tz":-480,"elapsed":1502,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"376bbdf3-9aef-452e-eca0-2a083909c897"},"outputs":[{"output_type":"stream","name":"stdout","text":["Here is the next number in the Fibonacci sequence after 8: 13.<|eot_id|>\n"]}],"source":["FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","messages = [\n","    {\"role\": \"user\", \"content\": \"Continue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,\"},\n","]\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize = True,\n","    add_generation_prompt = True, # Must add for generation\n","    return_tensors = \"pt\",\n",").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n","_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n","                   use_cache = True, temperature = 1.5, min_p = 0.1)"]},{"cell_type":"markdown","metadata":{"id":"uMuVrWbjAzhc"},"source":["<a name=\"Save\"></a>\n","### Saving, loading finetuned models\n","To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n","\n","**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"upcOlWe7A1vc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730442905521,"user_tz":-480,"elapsed":2162,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"d6eacd4e-6ccb-4f78-8e32-61381169521a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('lora_model/tokenizer_config.json',\n"," 'lora_model/special_tokens_map.json',\n"," 'lora_model/tokenizer.json')"]},"metadata":{},"execution_count":26}],"source":["model.save_pretrained(\"lora_model\") # Local saving\n","tokenizer.save_pretrained(\"lora_model\")\n","# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n","# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"]},{"cell_type":"markdown","metadata":{"id":"AEEcJ4qfC7Lp"},"source":["Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"MKX_XKs_BNZR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730443497393,"user_tz":-480,"elapsed":18422,"user":{"displayName":"AION JACK","userId":"16959933713583510605"}},"outputId":"2b5137db-7fe2-425b-c49b-2df7e4d7fa24"},"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2024.10.7: Fast Llama patching. Transformers = 4.44.2.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 7.5. CUDA Toolkit = 12.4.\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","Sure, I can help with data analysis. Please provide the data you need to analyze and I will be happy to assist you in any way I can.<|eot_id|>\n"]}],"source":["if True:\n","    from unsloth import FastLanguageModel\n","    model, tokenizer = FastLanguageModel.from_pretrained(\n","        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","        max_seq_length = max_seq_length,\n","        dtype = dtype,\n","        load_in_4bit = load_in_4bit,\n","    )\n","    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","messages = [\n","    {\"role\": \"user\", \"content\": \"can you help me with data analysis ?\"},\n","]\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize = True,\n","    add_generation_prompt = True, # Must add for generation\n","    return_tensors = \"pt\",\n",").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n","_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n","                   use_cache = True, temperature = 1.5, min_p = 0.1)"]},{"cell_type":"markdown","metadata":{"id":"QQMjaNrjsU5_"},"source":["You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFfaXG0WsQuE"},"outputs":[],"source":["if False:\n","    # I highly do NOT suggest - use Unsloth if possible\n","    from peft import AutoPeftModelForCausalLM\n","    from transformers import AutoTokenizer\n","    model = AutoPeftModelForCausalLM.from_pretrained(\n","        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","        load_in_4bit = load_in_4bit,\n","    )\n","    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"]},{"cell_type":"markdown","metadata":{"id":"f422JgM9sdVT"},"source":["### Saving to float16 for VLLM\n","\n","We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHjt_SMYsd3P"},"outputs":[],"source":["# Merge to 16bit\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n","if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n","\n","# Merge to 4bit\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n","if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n","\n","# Just LoRA adapters\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n","if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"]},{"cell_type":"markdown","metadata":{"id":"TCv4vXHd61i7"},"source":["### GGUF / llama.cpp Conversion\n","To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n","\n","Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n","* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n","* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n","* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n","\n","[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqfebeAdT073"},"outputs":[],"source":["# Save to 8bit Q8_0\n","if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n","# Remember to go to https://huggingface.co/settings/tokens for a token!\n","# And change hf to your username!\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n","\n","# Save to 16bit GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n","\n","# Save to q4_k_m GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n","\n","# Save to multiple GGUF options - much faster if you want multiple!\n","if False:\n","    model.push_to_hub_gguf(\n","        \"hf/model\", # Change hf to your username!\n","        tokenizer,\n","        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n","        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n","    )"]},{"cell_type":"markdown","metadata":{"id":"bDp0zNpwe6U_"},"source":["Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in `llama.cpp` or a UI based system like `GPT4All`. You can install GPT4All by going [here](https://gpt4all.io/index.html).\n","\n","**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"]},{"cell_type":"markdown","metadata":{"id":"Zt9CHJqO6p30"},"source":["And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/u54VK8m8tk) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n","\n","Some other links:\n","1. Zephyr DPO 2x faster [free Colab](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)\n","2. Llama 7b 2x faster [free Colab](https://colab.research.google.com/drive/1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5?usp=sharing)\n","3. TinyLlama 4x faster full Alpaca 52K in 1 hour [free Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)\n","4. CodeLlama 34b 2x faster [A100 on Colab](https://colab.research.google.com/drive/1y7A0AxE3y8gdj4AVkl2aZX47Xu3P1wJT?usp=sharing)\n","5. Mistral 7b [free Kaggle version](https://www.kaggle.com/code/danielhanchen/kaggle-mistral-7b-unsloth-notebook)\n","6. We also did a [blog](https://huggingface.co/blog/unsloth-trl) with ü§ó HuggingFace, and we're in the TRL [docs](https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth)!\n","7. `ChatML` for ShareGPT datasets, [conversational notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing)\n","8. Text completions like novel writing [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)\n","9. [**NEW**] We make Phi-3 Medium / Mini **2x faster**! See our [Phi-3 Medium notebook](https://colab.research.google.com/drive/1hhdhBa1j_hsymiW9m-WzxQtgqTH_NHqi?usp=sharing)\n","10. [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n","11. [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)\n","12. [**NEW**] We make Mistral NeMo 12B 2x faster and fit in under 12GB of VRAM! [Mistral NeMo notebook](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)\n","\n","<div class=\"align-center\">\n","  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n","  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n","  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Support our work if you can! Thanks!\n","</div>"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1T5-zKWM_5OD21QHwXHiV9ixTRR7k3iB9","timestamp":1730291644378},{"file_id":"15OyFkGoCImV9dSsewU1wa2JuKB4-mDE_","timestamp":1727333957154},{"file_id":"1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp","timestamp":1724446900756},{"file_id":"135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp","timestamp":1721714808667},{"file_id":"10NbwlsRChbma1v55m8LAPYG15uQv6HLo","timestamp":1713459337061},{"file_id":"1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_","timestamp":1708958229810},{"file_id":"1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5","timestamp":1703608159823},{"file_id":"1oW55fBmwzCOrBVX66RcpptL3a99qWBxb","timestamp":1702886138876}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"36981726dc404df8874bb0796084bced":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05fd433f8f484e55afea57b3c1384ff3","IPY_MODEL_cbb84ef62bab4326a6c410e8882c8014","IPY_MODEL_fc34d081a93c4b29a5dcb778b3555cf6"],"layout":"IPY_MODEL_51dc48b88ca1452bbb9aa0b679f0af45"}},"05fd433f8f484e55afea57b3c1384ff3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd9a30b2e2504739b9b3a2f35c0dc3d3","placeholder":"‚Äã","style":"IPY_MODEL_92a90693e6dc4836b144d83340030e14","value":"model.safetensors:‚Äá100%"}},"cbb84ef62bab4326a6c410e8882c8014":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_82c7d899dd18448dbbcd552ba9cf8c15","max":2242762780,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae5b1c23929f4778bb44530b150b69e5","value":2242762567}},"fc34d081a93c4b29a5dcb778b3555cf6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5e37d00bf0247a0b4f0b9644ae21d1d","placeholder":"‚Äã","style":"IPY_MODEL_62f93eb313cc4d79ad21deb4b3041351","value":"‚Äá2.24G/2.24G‚Äá[00:27&lt;00:00,‚Äá337MB/s]"}},"51dc48b88ca1452bbb9aa0b679f0af45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd9a30b2e2504739b9b3a2f35c0dc3d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92a90693e6dc4836b144d83340030e14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82c7d899dd18448dbbcd552ba9cf8c15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae5b1c23929f4778bb44530b150b69e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5e37d00bf0247a0b4f0b9644ae21d1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62f93eb313cc4d79ad21deb4b3041351":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c19e4a642f4d469cba01f58b43ba10e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2148b67075f84b398edbe2bb8240a465","IPY_MODEL_35791f89229048698e2c890b8df8e305","IPY_MODEL_8192e352cf1e4687b3c324f4d6f15292"],"layout":"IPY_MODEL_e1a84d7f539e48c7a4e10181b3ee9e4c"}},"2148b67075f84b398edbe2bb8240a465":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6524d8a70cb428b8768a9b14dceea24","placeholder":"‚Äã","style":"IPY_MODEL_780d14f6163e4cb5806354c7cc7ff64f","value":"generation_config.json:‚Äá100%"}},"35791f89229048698e2c890b8df8e305":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b10aeec1a7cc41c5bedcdf785cad0fd8","max":184,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4896e0401df480d9c7a0fc4aa1af3b8","value":184}},"8192e352cf1e4687b3c324f4d6f15292":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b874df1fcf84b09b90ea8d01c775a72","placeholder":"‚Äã","style":"IPY_MODEL_f87b04b496d546878d2cb80b592012de","value":"‚Äá184/184‚Äá[00:00&lt;00:00,‚Äá13.1kB/s]"}},"e1a84d7f539e48c7a4e10181b3ee9e4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6524d8a70cb428b8768a9b14dceea24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"780d14f6163e4cb5806354c7cc7ff64f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b10aeec1a7cc41c5bedcdf785cad0fd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4896e0401df480d9c7a0fc4aa1af3b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b874df1fcf84b09b90ea8d01c775a72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f87b04b496d546878d2cb80b592012de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e3e4c8d3ffb46bf85c83606f20e4d93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30676ce5eab14ebbb01160109cb33b5b","IPY_MODEL_e2d4b8ff64da4dc6a9c2ba693efc2d2b","IPY_MODEL_f7bb0b34d2f74c94a22f940c40bdee58"],"layout":"IPY_MODEL_f9fe991293344132a3f9ae365b1c01ad"}},"30676ce5eab14ebbb01160109cb33b5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17faddb1f5bf4180a203847b32b2ab5b","placeholder":"‚Äã","style":"IPY_MODEL_e23de6c4f0fc4b81aa7d8acb48b21216","value":"tokenizer_config.json:‚Äá100%"}},"e2d4b8ff64da4dc6a9c2ba693efc2d2b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b225dc5593a4f8ea4148a7c9e27c75f","max":54598,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a91f987509a546ce8a66248fa66a1a46","value":54598}},"f7bb0b34d2f74c94a22f940c40bdee58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_747e2dc242014fecb41f2aa32e664192","placeholder":"‚Äã","style":"IPY_MODEL_cb9a690d5fad40d0845d511d0b1b124e","value":"‚Äá54.6k/54.6k‚Äá[00:00&lt;00:00,‚Äá2.43MB/s]"}},"f9fe991293344132a3f9ae365b1c01ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17faddb1f5bf4180a203847b32b2ab5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e23de6c4f0fc4b81aa7d8acb48b21216":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b225dc5593a4f8ea4148a7c9e27c75f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a91f987509a546ce8a66248fa66a1a46":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"747e2dc242014fecb41f2aa32e664192":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb9a690d5fad40d0845d511d0b1b124e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5e000d64d7a454da36486967ffc08c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0510cec2c45456b99ec434ef9b9157b","IPY_MODEL_411cda0f1a5e4b7e9d74f987c7a2b16a","IPY_MODEL_be2aafaefe814dcd9b13928273a7ba0d"],"layout":"IPY_MODEL_c47488089eb549a4b31044c572fe8eaa"}},"b0510cec2c45456b99ec434ef9b9157b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d00ab237213428faeb77de58d861670","placeholder":"‚Äã","style":"IPY_MODEL_ef82c23c6b0b4a75acad1a703150411c","value":"tokenizer.json:‚Äá100%"}},"411cda0f1a5e4b7e9d74f987c7a2b16a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c65a402ff025440b913ad3b83c1083fd","max":9085657,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c008bf66a39a4ea0b6e96621cd7f60b6","value":9085657}},"be2aafaefe814dcd9b13928273a7ba0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ac66aced16a40ee92aa346863bedf99","placeholder":"‚Äã","style":"IPY_MODEL_d05270121965414982167926a327be7c","value":"‚Äá9.09M/9.09M‚Äá[00:00&lt;00:00,‚Äá42.9MB/s]"}},"c47488089eb549a4b31044c572fe8eaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d00ab237213428faeb77de58d861670":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef82c23c6b0b4a75acad1a703150411c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c65a402ff025440b913ad3b83c1083fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c008bf66a39a4ea0b6e96621cd7f60b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ac66aced16a40ee92aa346863bedf99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d05270121965414982167926a327be7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a788f319dd1e4615a6a79ef69f034561":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1dceacc636e84c9fb1f791cd7d61443b","IPY_MODEL_b5e4cea070294f3ea30578bb0eafca2e","IPY_MODEL_57af8ebf0c964110878cb5881906231d"],"layout":"IPY_MODEL_d41cfc52350e41619550c5e4aa3fab5b"}},"1dceacc636e84c9fb1f791cd7d61443b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b2da0a983af4e2cbbdc23f7cebfe57b","placeholder":"‚Äã","style":"IPY_MODEL_98dc0478ab5142a9ad267948441d2dbe","value":"special_tokens_map.json:‚Äá100%"}},"b5e4cea070294f3ea30578bb0eafca2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6e713c99db94de198e03ce6b964dec6","max":454,"min":0,"orientation":"horizontal","style":"IPY_MODEL_444574265e6b4323a0cb164e95dc0ddc","value":454}},"57af8ebf0c964110878cb5881906231d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a065374ea0f409f87aa64fb72be47ab","placeholder":"‚Äã","style":"IPY_MODEL_274361260632487e90f9c32e82ee0dc3","value":"‚Äá454/454‚Äá[00:00&lt;00:00,‚Äá31.8kB/s]"}},"d41cfc52350e41619550c5e4aa3fab5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b2da0a983af4e2cbbdc23f7cebfe57b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98dc0478ab5142a9ad267948441d2dbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6e713c99db94de198e03ce6b964dec6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"444574265e6b4323a0cb164e95dc0ddc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a065374ea0f409f87aa64fb72be47ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"274361260632487e90f9c32e82ee0dc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dacc09fa32084dd4ac05c1fa6c659279":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f7d92a9b70a14f19a40e34082ace404f","IPY_MODEL_3f92dc6931e14b1187abf4d429eec0ca","IPY_MODEL_b421abc9b1d34422975aaeb73e1d8438"],"layout":"IPY_MODEL_fabb313182a842a787c501a0b588b3f7"}},"f7d92a9b70a14f19a40e34082ace404f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3acb5ec73704903a3cb2c12c97f9166","placeholder":"‚Äã","style":"IPY_MODEL_429d2b5b990f408d854e6b97e7d7f3ec","value":"Map:‚Äá100%"}},"3f92dc6931e14b1187abf4d429eec0ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7f1400c0da64a32b88ea92979f039e5","max":20324,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16b30041863a4fa6827768ea8c4307a4","value":20324}},"b421abc9b1d34422975aaeb73e1d8438":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2952fff73a0a4191a97f152d11e46453","placeholder":"‚Äã","style":"IPY_MODEL_90b3be7f36b34f468dbd925da6d022f8","value":"‚Äá20324/20324‚Äá[00:02&lt;00:00,‚Äá6775.94‚Äáexamples/s]"}},"fabb313182a842a787c501a0b588b3f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3acb5ec73704903a3cb2c12c97f9166":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"429d2b5b990f408d854e6b97e7d7f3ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7f1400c0da64a32b88ea92979f039e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16b30041863a4fa6827768ea8c4307a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2952fff73a0a4191a97f152d11e46453":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90b3be7f36b34f468dbd925da6d022f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5676a3c878a4cef81a99f98788465c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3db54d2307c64b35ae7157bf8b733d58","IPY_MODEL_4798e594e9594df5b63bce4b8e6dce18","IPY_MODEL_71dd64dcd81e4fe79e99dbdd3f804456"],"layout":"IPY_MODEL_8e7a93d448054905b7839f3a8cc8e1c9"}},"3db54d2307c64b35ae7157bf8b733d58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6251c41a3dd47b892077fab6113bcff","placeholder":"‚Äã","style":"IPY_MODEL_8d44da7875eb423eb1d2bb9623bb7bd0","value":"Map‚Äá(num_proc=2):‚Äá100%"}},"4798e594e9594df5b63bce4b8e6dce18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5beae692604e4460ae1975884955839e","max":20324,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18218191ebd54e87aa2cc6e4b80f6fc6","value":20324}},"71dd64dcd81e4fe79e99dbdd3f804456":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_541be1b16245403b97a9d03e0c5b72b4","placeholder":"‚Äã","style":"IPY_MODEL_ac60dce9cbd74d839c0ec3eb38fb7e25","value":"‚Äá20324/20324‚Äá[00:33&lt;00:00,‚Äá897.87‚Äáexamples/s]"}},"8e7a93d448054905b7839f3a8cc8e1c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6251c41a3dd47b892077fab6113bcff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d44da7875eb423eb1d2bb9623bb7bd0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5beae692604e4460ae1975884955839e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18218191ebd54e87aa2cc6e4b80f6fc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"541be1b16245403b97a9d03e0c5b72b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac60dce9cbd74d839c0ec3eb38fb7e25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0dcb6023d8e54723a1913eb205834d6a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e12ec3a0303b4871b56a26fde0e89b07","IPY_MODEL_bd20a87c57d04290b2808741d02b0a5c","IPY_MODEL_9250dacb867c4ac2b171367c406cdd6a"],"layout":"IPY_MODEL_8293e636a0d84aa7ad68de3b9601c490"}},"e12ec3a0303b4871b56a26fde0e89b07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50ea9655e9fa4f90b513334587ad5ec9","placeholder":"‚Äã","style":"IPY_MODEL_debb3d463a224f36b9e03a0121d9861e","value":"Map:‚Äá100%"}},"bd20a87c57d04290b2808741d02b0a5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4e8619ca0d848ac83b1d287c0ddf673","max":20324,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2fa1bf55bafb4f4fb26f5b0b5783ac43","value":20324}},"9250dacb867c4ac2b171367c406cdd6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dafbbef96d44849a2798dfdafb8f747","placeholder":"‚Äã","style":"IPY_MODEL_5620f476f6c14befbfcf77d48cbd3d39","value":"‚Äá20324/20324‚Äá[00:10&lt;00:00,‚Äá1899.16‚Äáexamples/s]"}},"8293e636a0d84aa7ad68de3b9601c490":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50ea9655e9fa4f90b513334587ad5ec9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"debb3d463a224f36b9e03a0121d9861e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4e8619ca0d848ac83b1d287c0ddf673":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fa1bf55bafb4f4fb26f5b0b5783ac43":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2dafbbef96d44849a2798dfdafb8f747":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5620f476f6c14befbfcf77d48cbd3d39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}